services:
  web:
    image: nginx:latest
    ports:
      - "${WEB_PORT:-80}:80"
    volumes:
      - ./src/ui:/usr/share/nginx/html
    depends_on:
      - rag
    restart: unless-stopped
    env_file:
      - .env

  rag: 
    build: ./src/rag
    ports:
      - "${API_EXTERNAL_PORT:-8000}:${API_PORT:-8000}"
    volumes:
      - ./src/rag:/app
    env_file:
      - .env
    depends_on:
      - vector-db
      - ollama
    restart: unless-stopped
    command: ["python", "main.py"]

  vector-db:
    image: qdrant/qdrant:latest
    ports:
      - "${QDRANT_REST_PORT:-6333}:6333"
      - "${QDRANT_GRPC_PORT:-6334}:6334"
    volumes:
      - vector_data:/qdrant/storage
    restart: unless-stopped
    env_file:
      - .env

  ollama:
    image: ollama/ollama:latest
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    env_file:
      - .env
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        ollama serve &
        sleep ${OLLAMA_STARTUP_DELAY:-5}
        for model in ${OLLAMA_MODELS:-qwen2.5:0.5b nomic-embed-text}; do
          ollama pull $model
        done
        wait
  
volumes:
  vector_data: {}
  ollama_data: {} 