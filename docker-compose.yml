services:
  web:
    image: nginx:latest
    ports:
      - "${WEB_PORT:-80}:80"
    volumes:
      - ./src/ui:/usr/share/nginx/html
    depends_on:
      - rag
    restart: unless-stopped
    env_file:
      - .env

  rag: 
    build: ./src/rag
    ports:
      - "${API_EXTERNAL_PORT:-8000}:${API_PORT:-8000}"
    volumes:
      - ./src/rag:/app
    env_file:
      - .env
    depends_on:
      - vector-db
      - ollama
    restart: unless-stopped
    command: ["python", "main.py"]

  vector-db:
    image: qdrant/qdrant:latest
    ports:
      - "${QDRANT_REST_PORT:-6333}:6333"
      - "${QDRANT_GRPC_PORT:-6334}:6334"
    volumes:
      - vector_data:/qdrant/storage
    restart: unless-stopped
    env_file:
      - .env

  ollama:
    image: ollama/ollama:latest
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    env_file:
      - .env
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        ollama serve &
        pid=$$!
        
        # Wait for server to start
        sleep $${OLLAMA_STARTUP_DELAY:-5}
        until ollama list >/dev/null 2>&1; do sleep 1; done
        
        # Pull models
        for model in $${OLLAMA_MODELS:-qwen2.5:0.5b nomic-embed-text}; do
          echo "Pulling $$model..."
          ollama pull "$$model"
        done
        
        wait $$pid
  
volumes:
  vector_data: {}
  ollama_data: {} 