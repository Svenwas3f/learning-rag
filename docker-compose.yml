services:
  web:
    image: nginx:latest
    ports:
      - "${WEB_PORT:-80}:80"
    volumes:
      - ./src/ui:/usr/share/nginx/html
    depends_on:
      - rag
    restart: unless-stopped
    env_file:
      - .env

  rag: 
    build: ./src/rag
    ports:
      - "${API_EXTERNAL_PORT:-8000}:${API_PORT:-8000}"
    volumes:
      - ./src/rag:/app
    env_file:
      - .env
    depends_on:
      - vector-db
      - ollama
    restart: unless-stopped
    command: ["python", "main.py"]

  vector-db:
    image: qdrant/qdrant:latest
    ports:
      - "${QDRANT_REST_PORT:-6333}:6333"
      - "${QDRANT_GRPC_PORT:-6334}:6334"
    volumes:
      - vector_data:/qdrant/storage
    restart: unless-stopped
    env_file:
      - .env

  ollama:
    image: ollama/ollama:latest
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    env_file:
      - .env
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        # Start ollama in the background
        ollama serve &
        OLLAMA_PID=$$!
        
        # Wait for ollama to be ready
        echo "Waiting for Ollama server to be ready..."
        sleep $${OLLAMA_STARTUP_DELAY:-5}
        
        # Health check - wait until server is responding
        MAX_RETRIES=30
        RETRY_COUNT=0
        until ollama list > /dev/null 2>&1 || [ $$RETRY_COUNT -eq $$MAX_RETRIES ]; do
          echo "Waiting for Ollama server... ($$RETRY_COUNT/$$MAX_RETRIES)"
          sleep 2
          RETRY_COUNT=$$((RETRY_COUNT + 1))
        done
        
        if [ $$RETRY_COUNT -eq $$MAX_RETRIES ]; then
          echo "ERROR: Ollama server failed to start"
          exit 1
        fi
        
        echo "Ollama server is ready"
        
        # Pull models
        echo "Starting model downloads..."
        for model in $${OLLAMA_MODELS:-qwen2.5:0.5b nomic-embed-text}; do
          if [ -n "$$model" ]; then
            echo "Pulling model: $$model"
            ollama pull "$$model" || echo "Failed to pull model: $$model"
          fi
        done
        echo "Model downloads complete."
        
        # Keep the container running
        wait $$OLLAMA_PID
  
volumes:
  vector_data: {}
  ollama_data: {} 